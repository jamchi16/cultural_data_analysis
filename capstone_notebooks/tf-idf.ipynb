{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386f8ca5-5e8b-4ed4-98e0-2b980fe9d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from htrc_features import Volume\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b15c0a-2e77-4f12-ad0c-94c82d351543",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = pd.read_csv('../articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a5fe20-b7b4-437e-9ec4-240e26ee744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "         'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "         'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "         'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "         'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "         'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "         'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "         'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "         'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "         'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "         'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "         'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'also', \"!\", \"it's\",\"user\", \"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b56bbcea-8e74-4b81-a5b3-b0a41c8da9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to keep track of the number of articles each word appears in\n",
    "word_article_count = {}\n",
    "# Initialize Counter to keep track of the frequency of each word\n",
    "word_freq = Counter()\n",
    "\n",
    "# Iterate through each row in the tweet DataFrame\n",
    "for idx, row in article_df.iterrows():\n",
    "    # Get the text of the tweet, convert it to lowercase, and split into individual words (tokens)\n",
    "    text = row['text']\n",
    "    tokens = text.lower().split()\n",
    "    \n",
    "    # Get the unique set of tokens to avoid counting the same word multiple times in the same article\n",
    "    unique_tokens = set(tokens)\n",
    "    \n",
    "    # Update the word frequency counter with all tokens\n",
    "    word_freq.update(tokens)\n",
    "    \n",
    "    # For each unique token, increment the tweet count in which the word appears\n",
    "    for token in unique_tokens:\n",
    "        if not token in word_article_count.keys():\n",
    "            word_article_count[token] = 0\n",
    "        word_article_count[token] += 1\n",
    "\n",
    "# Create a DataFrame from the word frequency counter\n",
    "word_freq_df = pd.DataFrame(list(word_freq.items()), columns=['Word', 'Frequency'])\n",
    "\n",
    "# Add a new column to the DataFrame for the number of tweets each word is mentioned in\n",
    "word_freq_df['Articles Mentioned'] = word_freq_df['Word'].apply(lambda x: word_article_count[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db53379-2f89-4b07-8d9a-b106e6b3a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF function\n",
    "def calculate_tfidf(word_freq, total_articles, articles_mentioned):\n",
    "    idf = np.log((total_articles) / (articles_mentioned)) + 1\n",
    "    return word_freq * idf\n",
    "\n",
    "# Apply function to dataframe rows\n",
    "word_freq_df['TF-IDF'] = word_freq_df.apply(lambda row: calculate_tfidf(row['Frequency'], len(article_df), row['Articles Mentioned']), axis=1)\n",
    "\n",
    "# Remove rows with stop words\n",
    "word_freq_df = word_freq_df[~word_freq_df['Word'].isin(STOPS)]\n",
    "\n",
    "# Remove all non-letter rows\n",
    "word_freq_df = word_freq_df[word_freq_df['Word'].str.contains(r'[a-zA-Z]', regex=True)]\n",
    "\n",
    "# Sort by TF-IDF for display\n",
    "word_freq_df = word_freq_df.sort_values(by='TF-IDF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0eae594-c8cc-42f0-8a77-ccc046089c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Articles Mentioned</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>learning</td>\n",
       "      <td>2026</td>\n",
       "      <td>256</td>\n",
       "      <td>2582.958514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>data</td>\n",
       "      <td>1966</td>\n",
       "      <td>259</td>\n",
       "      <td>2483.559072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>neural</td>\n",
       "      <td>1500</td>\n",
       "      <td>206</td>\n",
       "      <td>2238.310142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>network</td>\n",
       "      <td>1288</td>\n",
       "      <td>184</td>\n",
       "      <td>2067.429558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>machine</td>\n",
       "      <td>1481</td>\n",
       "      <td>237</td>\n",
       "      <td>2002.345751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>one</td>\n",
       "      <td>1654</td>\n",
       "      <td>297</td>\n",
       "      <td>1862.984209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>model</td>\n",
       "      <td>897</td>\n",
       "      <td>143</td>\n",
       "      <td>1665.942755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>would</td>\n",
       "      <td>1230</td>\n",
       "      <td>250</td>\n",
       "      <td>1597.305075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>like</td>\n",
       "      <td>1413</td>\n",
       "      <td>298</td>\n",
       "      <td>1586.784084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>deep</td>\n",
       "      <td>991</td>\n",
       "      <td>187</td>\n",
       "      <td>1574.673545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>ai</td>\n",
       "      <td>846</td>\n",
       "      <td>144</td>\n",
       "      <td>1565.328108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>it’s</td>\n",
       "      <td>1188</td>\n",
       "      <td>247</td>\n",
       "      <td>1557.105177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>use</td>\n",
       "      <td>1172</td>\n",
       "      <td>270</td>\n",
       "      <td>1431.786658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>image</td>\n",
       "      <td>660</td>\n",
       "      <td>109</td>\n",
       "      <td>1404.965132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>training</td>\n",
       "      <td>788</td>\n",
       "      <td>157</td>\n",
       "      <td>1389.903655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>using</td>\n",
       "      <td>1025</td>\n",
       "      <td>258</td>\n",
       "      <td>1298.801429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>new</td>\n",
       "      <td>949</td>\n",
       "      <td>237</td>\n",
       "      <td>1283.069627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>human</td>\n",
       "      <td>667</td>\n",
       "      <td>153</td>\n",
       "      <td>1193.693221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>need</td>\n",
       "      <td>817</td>\n",
       "      <td>216</td>\n",
       "      <td>1180.405295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>get</td>\n",
       "      <td>837</td>\n",
       "      <td>233</td>\n",
       "      <td>1145.890227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Frequency  Articles Mentioned       TF-IDF\n",
       "640   learning       2026                 256  2582.958514\n",
       "1049      data       1966                 259  2483.559072\n",
       "1776    neural       1500                 206  2238.310142\n",
       "1997   network       1288                 184  2067.429558\n",
       "188    machine       1481                 237  2002.345751\n",
       "80         one       1654                 297  1862.984209\n",
       "1406     model        897                 143  1665.942755\n",
       "71       would       1230                 250  1597.305075\n",
       "473       like       1413                 298  1586.784084\n",
       "1545      deep        991                 187  1574.673545\n",
       "643         ai        846                 144  1565.328108\n",
       "359       it’s       1188                 247  1557.105177\n",
       "291        use       1172                 270  1431.786658\n",
       "2253     image        660                 109  1404.965132\n",
       "3332  training        788                 157  1389.903655\n",
       "386      using       1025                 258  1298.801429\n",
       "22         new        949                 237  1283.069627\n",
       "749      human        667                 153  1193.693221\n",
       "1094      need        817                 216  1180.405295\n",
       "189        get        837                 233  1145.890227"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e27ec0-cf7a-4235-8afb-53250dd6e2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
